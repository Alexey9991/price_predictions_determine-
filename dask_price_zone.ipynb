{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd \n",
    "import h3\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "from shapely.geometry import Point\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from shapely.geometry import Polygon\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "import dask.dataframe as dd\n",
    "\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "#   Драйвер подключения к БД\n",
    "engine = create_engine('')\n",
    "sql = '''\n",
    "\n",
    "\n",
    "'''\n",
    "df = pd.read_sql(sql, con=engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['area_price'] > 500]\n",
    "df['link_id'] = df['link'].apply(lambda x: x.split('_')[-1])\n",
    "df['timestamp'] = pd.to_datetime(df['date_id'])\n",
    "df = df.loc[df.groupby('link_id')['timestamp'].idxmax()]\n",
    "def get_first_word(text):\n",
    "  \"\"\"Возвращает первое слово из строки.\"\"\"\n",
    "  words = text.split()\n",
    "  if words:\n",
    "    return words[0]\n",
    "  else:\n",
    "    return ''  # Возвращаем пустую строку, если текст пустой\n",
    "\n",
    "# Создаем новую колонку 'first_word'\n",
    "df['class'] = df['title'].apply(get_first_word)\n",
    "df = df[df['class'] == 'Дом']\n",
    "\n",
    "\n",
    "unique_dates = df['timestamp'].unique()\n",
    "unique_dates.sort()\n",
    "\n",
    "test_dates = unique_dates[-1:]\n",
    "\n",
    "test_df = pd.DataFrame()\n",
    "test_df = df[df['timestamp'].isin(test_dates)]\n",
    "\n",
    "lists_of_dates = unique_dates[:-1]\n",
    "\n",
    "df = df[df['timestamp'].isin(lists_of_dates)]\n",
    "\n",
    "df['link_id'] = df['link'].apply(lambda x: x.split('_')[-1])\n",
    "df['timestamp'] = pd.to_datetime(df['date_id'])\n",
    "df = df.loc[df.groupby('link_id')['timestamp'].idxmax()]\n",
    "unique_dates = df['timestamp'].unique()\n",
    "unique_dates.sort()\n",
    "\n",
    "lists_of_dates = unique_dates[:-1]\n",
    "\n",
    "df = df[df['timestamp'].isin(lists_of_dates)]\n",
    "\n",
    "dates = pd.to_datetime(lists_of_dates)\n",
    "\n",
    "# Нахождение минимальной даты\n",
    "min_date = dates.min()\n",
    "# Вычитание минимальной даты из всех остальных и преобразование в дни\n",
    "days_list = (dates - min_date).days\n",
    "days_list = days_list.tolist()\n",
    "\n",
    "\n",
    "dataframes = []\n",
    "list_of_dfs = []\n",
    "for i in range(len(df['date_id'].unique())):\n",
    "    df_name = 'df' +'_'+ str(days_list[i])\n",
    "    list_of_dfs.append(df_name)\n",
    "    df_filtered = df[df['date_id'] == sorted(df['date_id'].unique())[i]]\n",
    "    #dataframes[df_name] = df[df['date_of_parsing'] == df['date_of_parsing'].unique()[i]]\n",
    "    dataframes.append(df_filtered)\n",
    "\n",
    "\n",
    "# удаляем выбросы (если стоимость за кв.м. рассматриваемого участка меньше в 6 раз или больше в 10 отсноительно 10 ближайших участков, участок удаляется)\n",
    "n_neighbors = 10 \n",
    "resolution = 7\n",
    "log_base = 2\n",
    "min_neigbors_count_sum = 4\n",
    "def drop_bad_values(df, n_neighbors):\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.longitude, df.latitude))\n",
    "    nn_model = NearestNeighbors(n_neighbors=n_neighbors)\n",
    "    nn_model.fit(gdf[['longitude', 'latitude']])\n",
    "    def calculate_averages(row):\n",
    "        _, indices = nn_model.kneighbors([[row['longitude'], row['latitude']]])\n",
    "        neighbors = gdf.iloc[indices[0][1:], :]\n",
    "        area_price_mean = neighbors['area_price'].median()\n",
    "        return pd.Series({'area_price_mean': area_price_mean})\n",
    "\n",
    "    averages = df.apply(calculate_averages, axis=1)\n",
    "    df[['area_mean']] = averages\n",
    "    df['realative_difference'] = df['area_price']/df['area_mean']\n",
    "    df = df[df['realative_difference'] >= 0.15]\n",
    "    df = df[df['realative_difference'] < 10]\n",
    "    df = df.drop(columns = ['realative_difference','area_mean'])\n",
    "    return df \n",
    "\n",
    "list_of_izs = [drop_bad_values(df, n_neighbors) for df in dataframes]\n",
    "concatenated_df = pd.concat(dataframes, ignore_index=True)\n",
    "concatenated_df = concatenated_df.drop(columns=['area_mean','realative_difference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаляем выбросы (если стоимость за кв.м. рассматриваемого участка меньше в 6 раз или больше в 10 отсноительно 10 ближайших участков, участок удаляется)\n",
    "n_neighbors = 10 \n",
    "resolution = 7\n",
    "log_base = 2\n",
    "min_neigbors_count_sum = 4\n",
    "def drop_bad_values(df, n_neighbors):\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.longitude, df.latitude))\n",
    "    nn_model = NearestNeighbors(n_neighbors=n_neighbors)\n",
    "    nn_model.fit(gdf[['longitude', 'latitude']])\n",
    "    def calculate_averages(row):\n",
    "        _, indices = nn_model.kneighbors([[row['longitude'], row['latitude']]])\n",
    "        neighbors = gdf.iloc[indices[0][1:], :]\n",
    "        area_price_mean = neighbors['area'].median()\n",
    "\n",
    "        return pd.Series({'area_mean': area_price_mean})\n",
    "\n",
    "    averages = df.apply(calculate_averages, axis=1)\n",
    "\n",
    "    df[['area_mean']] = averages\n",
    "    df['realative_difference'] = df['area']/df['area_mean']\n",
    "    df = df[df['realative_difference'] >= 0.15]\n",
    "    df = df[df['realative_difference'] < 10]\n",
    "    df = df.drop(columns = ['realative_difference','area'])\n",
    "    return df \n",
    "\n",
    "df_new = drop_bad_values(concatenated_df, n_neighbors) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h3_latlng_to_cell(lat, lng, resolution):\n",
    "    cell = h3.geo_to_h3(lat, lng, resolution)\n",
    "    return cell\n",
    "\n",
    "def from_cooordinates_to_hex(df, resolution):\n",
    "    df['hex_7'] = df.apply(lambda row: h3.geo_to_h3(row['latitude'], row['longitude'], resolution), axis=1)\n",
    "    return df\n",
    "\n",
    "geo_df_izs = from_cooordinates_to_hex(concatenated_df, resolution)\n",
    "\n",
    "geo_df_izs['count'] = geo_df_izs['hex_7'].map(geo_df_izs['hex_7'].value_counts())\n",
    "\n",
    "geo_df_izs['q1_area_price'], geo_df_izs['q3_area_price'] = geo_df_izs['area_price'], geo_df_izs['area_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_grouped = geo_df_izs.groupby('hex_7').agg({'area_price': 'median', 'count': 'max', }).reset_index()\n",
    "df_grouped = geo_df_izs.groupby('hex_7').agg(\n",
    "    area = ('area', 'median'),\n",
    "    area_price = ('area_price', 'median'),\n",
    "    count = ('count', 'max'),\n",
    "    q3_area_price = ('area_price', lambda x: x.quantile(0.75)),\n",
    "    q1_area_price = ('area_price', lambda x: x.quantile(0.25))\n",
    ").reset_index()\n",
    "\n",
    "df_grouped['mean_area_price'] = df_grouped['area_price']\n",
    "df_grouped = df_grouped.drop(columns = 'area_price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_grouped = dd.from_pandas(df_grouped, npartitions=10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_price_with_h3_neighbors(df, log_base, min_neigbors_count_sum):\n",
    "    df['log_price'] = df['mean_area_price'] * (df['count'].apply(lambda x: math.log(x, log_base)))\n",
    "    df['log_area'] = df['area'] * (df['count'].apply(lambda x: math.log(x, log_base)))\n",
    "    df['log_q1_price'] = df['q1_area_price'] * (df['count'].apply(lambda x: math.log(x, log_base)))\n",
    "    df['log_q3_price'] = df['q3_area_price'] * (df['count'].apply(lambda x: math.log(x, log_base)))\n",
    "    df['log_count'] = (df['count'].apply(lambda x: math.log(x, log_base)))\n",
    "\n",
    "    def calculate_for_row(row):\n",
    "        h3_index = row['hex_7']\n",
    "        try:\n",
    "            neighbors_indices = h3.k_ring(h3_index, 1)\n",
    "        except ValueError:\n",
    "            print(f\"Invalid H3 index: {h3_index}\")\n",
    "            return pd.Series([None, None, None, None, None, None])\n",
    "        neighbors_indices = h3.k_ring(h3_index, 1)\n",
    "        neighbors_indices = h3.k_ring(h3_index, 1)\n",
    "        neighbors_indices = [neighbor for neighbor in neighbors_indices if neighbor != h3_index]\n",
    "        neighbors_df = df[df['hex_7'].isin(neighbors_indices)]\n",
    "        summary_count = neighbors_df['count'].sum() + row['count']\n",
    "\n",
    "        if neighbors_df.empty or summary_count < min_neigbors_count_sum:\n",
    "            return pd.Series([row['mean_area_price'], 0, 0, row['q1_area_price'], row['q3_area_price'], summary_count])\n",
    "\n",
    "        mean_price = (row['mean_area_price']*row['count'] + neighbors_df['log_price'].sum())/(row['count']+neighbors_df['log_count'].sum())\n",
    "        q1_price = (row['q1_area_price']*row['count'] + neighbors_df['log_q1_price'].sum())/(row['count']+neighbors_df['log_count'].sum())\n",
    "        q3_price = (row['q3_area_price']*row['count'] + neighbors_df['log_q3_price'].sum())/(row['count']+neighbors_df['log_count'].sum())\n",
    "        return pd.Series([mean_price, q1_price, q3_price, row['q1_area_price'], row['q3_area_price'], summary_count])\n",
    "\n",
    "    result = df.apply(calculate_for_row, axis=1)\n",
    "    df[['mean_price_neighbors', 'q1_price', 'q3_price', 'q1_area_price_new', 'q3_area_price_new', 'summary_count_current_plus_neighbors']] = result\n",
    "    return df\n",
    "\n",
    "def get_mean_price(ddf, log_base, min_neigbors_count_sum):\n",
    "    ddf = ddf.map_partitions(\n",
    "        calculate_mean_price_with_h3_neighbors, \n",
    "        log_base=log_base, \n",
    "        min_neigbors_count_sum=min_neigbors_count_sum\n",
    "    )\n",
    "    return ddf\n",
    "\n",
    "# Пример использования (предполагая, что у вас есть Dask DataFrame `ddf_grouped`)\n",
    "ddf_grouped = get_mean_price(ddf_grouped, log_base, min_neigbors_count_sum)\n",
    "\n",
    "# Вычисление результата (если нужно)\n",
    "ddf_grouped = ddf_grouped.compute()\n",
    "\n",
    "ddf_grouped = ddf_grouped[ddf_grouped['summary_count_current_plus_neighbors'] > 3]\n",
    "ddf_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_neighbors_with_h3(gdf, hex_column='hex_7', k=1):\n",
    "  \"\"\"\n",
    "  Находит ближайшие гексы для каждого гекса в GeoDataFrame с помощью H3 k_ring.\n",
    "\n",
    "  Args:\n",
    "    gdf: GeoDataFrame с данными.\n",
    "    hex_column: Название столбца с номерами гексов.\n",
    "    k: Расстояние (в шагах) для поиска соседей.\n",
    "\n",
    "  Returns:\n",
    "    Множество с ID всех соседних гексов.\n",
    "  \"\"\"\n",
    "  neighbor_ids = set()\n",
    "\n",
    "  for hex_id in gdf[hex_column]:\n",
    "    # Находим соседей с помощью h3.k_ring\n",
    "    neighbors = h3.k_ring(hex_id, k)\n",
    "    neighbor_ids.update(neighbors)\n",
    "\n",
    "  return neighbor_ids\n",
    "\n",
    "neighbor_ids = find_neighbors_with_h3(ddf_grouped)\n",
    "\n",
    "def add_missing_hexes(df, all_neighbor_ids, hex_column='hex_7'):\n",
    "\n",
    "  missing_hexes = set(df[hex_column]) - all_neighbor_ids\n",
    "\n",
    "  if missing_hexes:\n",
    "    # Создаем новую строку с пустыми значениями\n",
    "    new_row = pd.Series({col: None for col in df.columns})\n",
    "    new_row[hex_column] = list(missing_hexes)  # Добавляем ID отсутствующих гексов\n",
    "\n",
    "    # Добавляем новую строку в DataFrame\n",
    "    df = df.append(new_row, ignore_index=True)\n",
    "\n",
    "  return df\n",
    "\n",
    "def add_missing_hexes_from_set(df, hex_set, hex_column='hex_7'):\n",
    "\n",
    "  existing_hexes = set(df[hex_column])\n",
    "  missing_hexes = hex_set - existing_hexes\n",
    "\n",
    "  if missing_hexes:\n",
    "    # Создаем DataFrame с отсутствующими гексами\n",
    "    new_df = pd.DataFrame({hex_column: list(missing_hexes)})\n",
    "\n",
    "    # Добавляем другие столбцы с пустыми значениями\n",
    "    for col in df.columns:\n",
    "      if col != hex_column:\n",
    "        new_df[col] = None\n",
    "  \n",
    "    # Объединяем DataFrame с исх одным\n",
    "    df = pd.concat([df, new_df], ignore_index=True)\n",
    "\n",
    "  return df\n",
    "\n",
    "df_with_missing = add_missing_hexes_from_set(ddf_grouped, neighbor_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_price_with_h3_neighbors(df, log_base, min_neigbors_count_sum, df_all):\n",
    "    def calculate_for_row(row):\n",
    "        h3_index = row['hex_7']\n",
    "        try:\n",
    "            neighbors_indices = h3.k_ring(h3_index, 1)\n",
    "        except ValueError:\n",
    "            print(f\"Invalid H3 index: {h3_index}\")\n",
    "            return pd.Series([None, None, None, None, None, None])\n",
    "        \n",
    "        # Удаляем текущий индекс из списка соседей\n",
    "        neighbors_indices = [neighbor for neighbor in neighbors_indices if neighbor != h3_index]\n",
    "        \n",
    "        # Получаем данные по соседям\n",
    "        neighbors_df = df_all[df_all['hex_7'].isin(neighbors_indices)]\n",
    "        \n",
    "        # Суммируем count соседей и текущий count\n",
    "        summary_count = neighbors_df['count'].sum() + row['count']\n",
    "        \n",
    "        if neighbors_df.empty or summary_count < min_neigbors_count_sum:\n",
    "            return pd.Series([row['mean_area_price'], 0, 0, row['q1_area_price'], row['q3_area_price'], summary_count])\n",
    "        \n",
    "        total_count = row['count'] + neighbors_df['log_count'].sum()\n",
    "        \n",
    "        mean_price = (row['mean_area_price'] * row['count'] + neighbors_df['log_price'].sum()) / total_count\n",
    "        q1_price = (row['q1_area_price'] * row['count'] + neighbors_df['log_q1_price'].sum()) / total_count\n",
    "        q3_price = (row['q3_area_price'] * row['count'] + neighbors_df['log_q3_price'].sum()) / total_count\n",
    "        \n",
    "        return pd.Series([mean_price, q1_price, q3_price, row['q1_area_price'], row['q3_area_price'], summary_count])\n",
    "\n",
    "    # Применяем вычисления к каждому ряду\n",
    "    result = df.apply(calculate_for_row, axis=1)\n",
    "    \n",
    "    # Присваиваем результаты в соответствующие колонки\n",
    "    df[['mean_price_neighbors', 'q1_price', 'q3_price', 'q1_area_price_new', 'q3_area_price_new', 'summary_count_current_plus_neighbors']] = result\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_mean_price(ddf, log_base, min_neigbors_count_sum, ddf_all):\n",
    "    # Применяем функцию к каждому разделу данных\n",
    "    ddf = ddf.map_partitions(\n",
    "        calculate_mean_price_with_h3_neighbors, \n",
    "        log_base=log_base, \n",
    "        min_neigbors_count_sum=min_neigbors_count_sum,\n",
    "        df_all=ddf_all\n",
    "    )\n",
    "    return ddf\n",
    "\n",
    "# Преобразуем в Dask DataFrame с более оптимальным числом партиций\n",
    "ddf_with_missing = dd.from_pandas(df_with_missing, npartitions=10)\n",
    "\n",
    "# Запуск с отображением прогресса\n",
    "with ProgressBar():\n",
    "    ddf_grouped = get_mean_price(ddf_with_missing, log_base, min_neigbors_count_sum, ddf_with_missing)\n",
    "    # Выполняем вычисления (при необходимости)\n",
    "    ddf_grouped = ddf_grouped.compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_with_missing = ddf_grouped\n",
    "ddf_with_missing = ddf_with_missing[ddf_with_missing['mean_price_neighbors'] != 0]\n",
    "ddf_with_missing.iloc[:, 2:-1] = ddf_with_missing.iloc[:, 2:-1].round()\n",
    "ddf_with_missing = ddf_with_missing[ddf_with_missing['summary_count_current_plus_neighbors'] > 3]\n",
    "ddf_with_missing = ddf_with_missing[['hex_7','area','q1_price','q3_price','mean_price_neighbors','summary_count_current_plus_neighbors']]\n",
    "ddf_with_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h3_to_polygon(hex_id):\n",
    "    geojson = h3.h3_to_geo_boundary(hex_id, geo_json=True)\n",
    "    return Polygon(geojson)\n",
    "\n",
    "# Преобразование 'hex_7' в геометрию\n",
    "ddf_with_missing['geometry'] = ddf_with_missing['hex_7'].apply(h3_to_polygon)\n",
    "\n",
    "# Создание GeoDataFrame\n",
    "geo_df = gpd.GeoDataFrame(ddf_with_missing, geometry='geometry')\n",
    "\n",
    "# Установка проекции (замените на нужную вам)\n",
    "geo_df.crs = 'epsg:4326' \n",
    "\n",
    "# Сохранение в GPKG\n",
    "geo_df.to_file(\"1608024_all_country_doma_dask.gpkg\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
